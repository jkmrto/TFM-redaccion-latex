%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Documento LaTeX 																						%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Título:		Capítulo 2
% Autor:  	Ignacio Moreno Doblas
% Fecha:  	2014-02-01
% Versión:	0.5.0
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapterbegin{Fundamentos Teóricos}
\label{chp:Utiliz}
%\minitoc

\par El trabajo realizado en este proyecto es englobado dentro de la temática denomiada visión por computador, dado que los métodos empleados se basan en la detección de patrónes sobre las imágenes dadas, en nuestro caso neuroimágenes. 

\par En el ámbito de la visión por computador cada imagen en sí misma es una muestra de miles dimensiones, cada uno de los pixeles. Un modelo generativo trata de capturar la relación entre las multiples dimensiones de los datos. En nuestro caso el modelo empleado para capturar dichas relaciones es el Autoencoder Variacional.

\par Es por ello que este capítulo se centrará en la exposición de este método en primer lugar. Dado el VAE esta fundamentado en el aprendizaje profundo, se dedicará la siguiente sección a las redes neuronales, haciendo especial hincapie a aquellas empleadas en este trabajo. Finalmente se expondrán brevemente los métodos estadísticos usados de manera auxiliar a lo largo de este proyecto.  

\section{Autoencoder Variacional}

\par Este apartado está dedicado a la exposición del  Autoencoder Variacional desde una perspectiva meramente teórica  con objeto de mostrar los fundamentos y, en última instancia, la capacidad de convergencia del método, basada en una función objetivo sobre la cual se puede aplicar descenso en gradiente estocástico. 

\subsection{Modelo de Variables Latentes}

\par

\begin{figure}[htp]
\centering
\includegraphics[scale=0.25]{images/ModeloVariablesLatentes.png}
\caption{Modelo gráfico de variables latentes para el modelo generativo del VAE. $Z$ es el espacio de variables lo más similar posible a un distribución normal $(N(0,I))$. El elemento $\theta$ es el conjunto de parámetros que aplicados de manera funcional sobre las variables latentes son capaces de generar el conjunto muestral $X$ }
\label{latentes_variables}
\end{figure}

\par A lo largo del entrenamiento o la caracterización de un modelo generativo, la parte mas complicada es la extracción de las dependencias entre las múltiples dimensiones. Son estas relaciones multidimensionales las que permiten generar muestras artificiales pertenecientes a clases distintas. Se denomina variable latente, a las unidades del modelo generativo capaces de discernir entre las distintas clases, esto es, capacitan al modelo para generar elementos diferenciados.



\par Un modelo generativo es representativo de un espacio muestral $(X)$ si para cada una de las muestras de dicho espacio $(x)$ hay al menos alguna configuración de las variables latentes $(z)$ que genera un variable $(\hat{x})$ muy similar a la original. Formalmente, dada una función  $f(z, \theta)$ parametrizada por un vector $\theta$ en un espacio $\Theta$ tal que:
\begin{center}
\begin{equation} \label{eq:space}
f : 	Z \times \Theta  \rightarrow  X  
\end{equation}
\end{center}

\subsection{Modelo Probabilístico}
\par El objetivo es maximizar la probabilidad de cada $x$ de el espacio muestral de acuerdo con:
\begin{center}
\begin{equation} \label{eq:int_1}
P(X)  = \int_{}^{}P(X|z;\theta) 
\end{equation}
\end{center}
\par En la ecuación \ref{eq:int_1}, $f(z;\theta)$ es reemplazada por la distribución $P(X| z;\theta)$, la cual nos permite hacer explícita la dependencia de $X$ sobre $z$, debido a la probabilidad condicionada. 
La idea de detrás de dicha expresión es principio de máxima verosimilitud (ML, del inglés \textit{Maximum Likehood}), el cual indica que si el modelo es capaz de generar muestras del espacio $X$, entonces será probable que le modelo generativo construya muestras similares.

\par En el VAE, la función de probabilidad $P(X|z;\theta)$ es las siguiente:

\begin{center}
\begin{equation} \label{eq:p_x_gausiana}
P(X|z; \theta)  = N(X| f(z;\theta), \sigma^{2}*I) 
\end{equation}
\end{center}

\par El uso de una distribución gausiana nos permite emplear descenso en gradiente durante la optimización, con objeto de caracterizar el modelo. Esta caracterización permite incrementar $P(X)$, entendidada como la probabilidad global de generar algún tipo de muestra de dicho espacio. Esto no sería posible si esta función de probabilidad fuera una delta de Dirac. Es importante notar que es fundamental disponener de una función $P(X|z)$ que sea computable y continua sobre $\theta$.

\par Teóricamente, para la mayoría de los valores $z$, $P(X|z)$ será aproximadaente cero, y por lo tanto su contribuciónpara la estimación de $P(X)$ será prácticamente nula.

\subsection{Función Objetivo}

\par La principal idea en la que se fundamenta el VAE es en muestrear los valores de $z$ a partir de $X$, esto es, necesitamos una nueva función $Q(z|X)$ que nos permita generar el conjunto de valores del espacio $Z$ a paritr de $X$. Esto nos reduce el espacio de $Z$ ya que, teóricamente, este se verá limitado en $Q(z|X)$. En última instacia, esto nos permitirá estimar  $E[P(X|z)]$, siendo esta el valor esperado de la distribución de probabilidad de los valores de X generados. 
\par La relacion entre $E(P(X|z))$ y $P(X)$ es uno de los fundamentos de los métodos variacionales Bayesianos. Comencemos con la definición de la divergencia de KUllback-Leibler (\textit{KL}  o \textit{D}) entre una distribución $P(z|X)$ y $Q(z)$:


\begin{center}
\begin{equation} \label{eq:KL_1}
D[Q(z)||P(z|X)] = E[log(Q(x)) - log(P(z|X))] 
\end{equation}
\end{center}

\par La expresión anterior, ecuación  \ref{eq:KL_1}, es una medida no simétrica de la similitud o diferencia entre las dos funciones de probabilidad $P(X|z) y Q(z)$. Dicha expresión mide diferencia (o el extra de información) entre un coódigo $P(x)$ y uno $Q(z)$. Aplicando la regla de Bayes sobre la expresión anterior conseguimos dejarlo en función de $P(X)$ y $P(X|z)$:

\begin{center}
\begin{equation} \label{eq:KL_2}
D[Q(z)||P(z|X)] = E_{z}[log(Q(x)) - log(P(X|z)) - log(P(z)) + log(p(X))]  
\end{equation}
\end{center}

\par Ordenando la expresión anterior, y teniendo en cuenta que $log(p(X))$ no depende de $z$ por lo que puede salir del valor esperado:

\begin{center}
\begin{equation} \label{eq:KL_3}
log(p(X))- D[Q(z)||P(z|X)]  = E_{z}[log(P(X|z)]) - D[Q(z)||P(z)].  
\end{equation}
\end{center}

\par Llegados a este punto es importante notar que el espacio $X$ es fijo y por lo tanto también lo  es su función de probabilidad $P(X)$. No obstante $Q(z)$ puede ser cualquier distribución, siempre que nos permita generar $Z$ a partir de $X$.
\par Dado que en nuestro caso estamos intersados en inferir $P(X)$, es necesario generar una función $Q$ dependiente sobre $X$ que permita que la divergencia $D[Q(z)||P(z|X)]$ sea pequeña, esto es, haya la menor perdida de información entre ambas distribuciones.

 \begin{center}
\begin{equation} \label{eq:KL_4}
log(p(X))- D[Q(z|X)||P(z|X)]  = E_{z}[log(P(X|z)]) - D[Q(z|X)||P(z)].  
\end{equation}
\end{center}

\par La expresión anterior, ecuación \ref{eq:KL_4}, es la principal del VAE, por lo que es necesario examinarla detenidamente. Analizando cada término por separado:
\begin{itemize}
\item La expresión de la izquierda representa la cantidad que se prentende maximizar: $log(P(x))$, mas un término de error reperesentado por D[Q(z)||P(z|X)] que es la capacidad de generar $z$ a partir de $X$. Este término de error será disminuido si $Q$ es de alta capacidad. 
\par Se trata de maximizar $log(P(X))$ mientras simultaneamente $D[Q(z|X)||P(z)]$ se minimiza . El término de probabilidad $P(z|X)$ no es computable analíticamente, describe la distribución de valores de $z$ que son capacades de generar $X$.
\item La expresión de la derecha es lo que se pretende optimar mediante el descenso en gradiente, dada una correcta seleccion de $Q(x)$.
\par Este segundo término fuerza la similitud entre $(Q(z|X))$ y$ P(X|z)$. Asumiendo que el término $Q(z|X)$ es de alta capacidad, tendrémos que el término de divergencia KL será cercano a cero. En última instancia, conseguiremos manejar de forma ana?itica $P(z|X)$ gracias a su similitud con $Q(z|X)$ 
\end{itemize}

\subsection{Optimización de la función objetivo}

\par Con objeto de poder realizar el descenso en gradiente sobre la expresión de la derecha de la ecuación \ref{eq:KL_4}, necesitamos definir de manera más exacta la forma de $Q(z|X)$. La elección habiutual es la siguiente:

 \begin{center}
\begin{equation} \label{eq:OFU_1}
Q(z|X)  = N(z|\mu(X;\vartheta), \Sigma(X; \vartheta))  
\end{equation}
\end{center}

donde $\mu$ y $\Sigma$ son funciones determistas con una serie de parámetros $\vartheta$ (en las siguientes expresiones se omitirá $\vartheta$). Normalmente tanto $\mu$ como $\Sigma$ son implementados mediante redes neuronales y $\Sigma$ esta limitada a un función diagonal, que permite facilitar los cálculos.

\par El segundo término de la expersion \ref{eq:KL_4}, $D[Q(z|X)||P(z)]$, al ser una divergencia KL entre dos funciones de gausianas multivaradas queda definda por:


 \begin{align*}
 \begin{split}
D(N(\mu_{0}(X), \Sigma_{0}(X)|| N(\mu_{1}(X), \Sigma_{1}(X)))  = \\
\frac{1}{2}\left(tr(\Sigma_{1}^{-1}\Sigma_{0}) + (\mu_{1} - \mu_{0})^{T} \Sigma_{1}^{-1}(\mu_{1} - \mu_{0}) - k + log (\frac{det\Sigma_{1}}{det\Sigma_{0}})  \right)
\end{split} 
 \end{align*}  \label{eq:OFU_2}
 
donde $k$ es la dimensionalidad de la distribución, la expresión queda de la siguiente manera:

 \begin{align}
 \begin{split}
D[N(\mu(X), \Sigma(X)) || N(0, I))] = \\
\frac{1}{2} \left( tr(\Sigma(X)) + (\mu(X))^{T}(\mu(X) - k -log(det(\Sigma(X)))) \right)
\end{split} 
 \end{align}  \label{eq:OFU_3}

\par El primer término de la expresion \ref{eq:KL_4}, $E_{z}[log(P(X|z))]$, es algo más complicado de determinar, aunque a priori se podría estimar usando un número suficentes de $z$ y aplicando al función $f$ asociada a $P(X|z)$, aunque esto sería tremendamente costoso computacionalmente. 
\par En  su lugar, se aplica un procedimiento denomidado Descenso en Gradiente Estocástico (SGD, del inglés \textit{Stochastic Gradient Descent}), que se basa en tomar úmicamente un valor de $z$ aplicarlo sobre $P(X|z)$, por lo que se obtendría una aproximación de $E_{z}[log(P(X|z))]$. Durante este proceso, estamos tomando como referencia cada una de las muestras $X$ de un conjunto de datos $D$ a la hora de estimar el error. Teniendo en cuento esto, la ecuación completa que se pretnede optimizar es:

 \begin{align}
 \begin{split}
E_{X}[log(P(X)) - D[Q(z|X) || P(z| X)]] = \\
E_{X}[E_{z}[log(P(X|z))] - D[Q(z|X) || P(z)]]
\end{split} 
 \end{align}  \label{eq:OFU_4}

\par Tomando el gradiente de la expresión anterior, reducimos la expresión a los valores internos de las esperanzas. Además, podemos tomar un único valor de $X$ y un único valor de $z$ de la distribución $Q(z|X)$, lo que no nos permite hacer computable el gradiente de la siguiente forma: 

 \begin{center}
\begin{equation} \label{eq:OFU_5}
log(P(X|z)) - D[Q(z|X) || P(z)]. 
\end{equation}
\end{center}

\par No obstante hay un problema significativo en la ecuación \ref{eq:OFU_4} ya que $E_{z}[log(P(X|z))]$
depende de los parámetros de $P$ y también de los valores de $Q$. Esto es problemático a la hora de realizar el descenso en gradiente, quedando resuelto con lo que se conoce como "Truco de Reparametrización".

\subsection{El truco de Reparametrización} \label{sec:repa_1}

\begin{figure}[htp]
\centering
\includegraphics[scale=0.4]{images/trucoReparametrizacion.png}
\caption{(Izquierda) Modelo de VAE sin Truco de Reparametrización. (Derecha) Modelo de VAE con Truco de Reparametrización}
\label{fig:repara_trick}
\end{figure}

\par Para garantizar el correcto funcionamiento del VAE es necesario que la función codificadora ($f$) asociada a $Q(z|X)$ generare un conjunto $Z$ capaz de ser decodificado por la función generadora ($g$) asociada a $P(X|z)$.
\par Analizando el problema desde otra perspectiva, tomando como referencia el diagrama de izquierda de la figura \ref{fig:repara_trick}. El paso hacia delante\footnote{En el ámbito de las redes neuronales se denomina paso hacia delante (del ingés \textit{forward pass}) al proceso incial de evaluar la salida generada a partir de una determinada entrada. En nuestro caso la entrada es $X$ y la salida $f(z)$, siendo la evaluación realizada $||X - f(z)||$} funciona de manera de correcta y es de esperar (si los parámetros están correctamente entrenados) que la salida produzca un salida acertada de manera general. 
\par No obstante, es necesario realizar el paso hacia atrás\footnote{En el ámbito de las redes neuronales, el paso hacia atrás (del inglés \textit{backpropagation}) hace referencia al proceso de evaluar el gradiente en cada uno de los elementos del sistema, tomando como referencia que el error se?a el determinado del paso hacia delante} teniendo que determinar el gradiente sobre la función $Q(z|X)$ encargada de generar $z$, pero este modelo de generación esta basado en el mapeo sobre una distribución gausiana, lo cual es una función no continua.

\par La solución a este problema se denomica truco de reparametrización (del inglés \textit{reparameterization trick}) el cual se basa en trasladar el mapeo sobre la distribución gausiana a una capa de entrada. 
\par Dados $\mu_{X}$ y  $\Sigma_{X}$, media y convarianza respectivamente de $Q(z|X)$, podemos mapear $N(\mu_{X}, \sigma(X))$ tomando un valor de la función Normal ($\epsilon \sim N(0,I)$) y aplicando la siguiente expresión:

\begin{center}
\begin{equation} \label{eq_trucoParametrizacion}
z = \mu(X) + \Sigma(X)^{1/2} * \epsilon. 
\end{equation}
\end{center}

\par Por lo tanto la función final, la cual queda representada en el diagrama de la derecha de la figura  \ref{fig:repara_trick}, sobre la que se aplica el gradiente es la siguiente:

 \begin{align}
 \begin{split}
E_{X\sim Z}\left[E_{\epsilon\sim N(0,I)}[log(P(X|z = \mu(X) + \Sigma^{1/2} * \epsilon))] - D[Q(z|X) || P(z)]\right].
\end{split} 
 \end{align}  \label{eq:RT_2}

\par Cabe notar que ninguna de las esperanzas son con respecto a las distribuciones características del sistema (ni $P(X|z)$ ni $Q(z|X)$) lo que nos permite realizar el gradiente sin ningún problema sobre los elementos contenidos dentro de los valores esperados, ya que el gradiente es la derivada sobre los parámetros funcionales de estas distribuciones.
\par Por lo tanto dado un valor de $X$ y $\epsilon$ la función \ref{eq:RT_2} será continua y determinista sobre los parámetros de $P$ y $Q$, lo cual nos permite realzar el paso hacia atrás de manera eficaz. 
 
 

 
\subsection{Interpretación de la función objetivo} \label{sec_funcionObjetivo} 
\par La función de pérdidas de un VAE se identifica con el logarítmo negativo de la probabilidad de verosimilitud con un regularizador. Se puede descomponer la función de pérdidas en términos de la pérdida asociada a cada una de las muestrsa $l_{i}$. Por lo tanto dicha función tendrá la siguiente forma $\sum_{i=1}^{N} l_{i}$ para las $N$ muestras totales. La función de pérdidas $l_{i}$ para una muestra $x_{i}$ será:

\begin{center}
\begin{equation} \label{eq:InterpretacionFuncionObjetivo}
l_{i}(\theta , \phi) =  -E_{z}[log_{p_{\phi}}(x_{i}|z)] + KL(q_{\theta}(z|x_{i})||p(z))
\end{equation}
\end{center}


\par El primer término es la pérdida de reconstrucción, más precisamente  se trata del logarítmo negativo del valor de verosimilitud de la muestra $i$. Este valor esperado está tomado con respecto a la distribución generada por el codfificador (es decir el espacio latente generado) para la muestra $i$ dada. Este término implica que el decoficador tratará de reconstruir de la manera más precisa posible la muestra en cuestión. Si la muestra generada por el codificador es muy distinta de la original conllevará una alta penalización en la pérdidas.

\par El segundo término es el regularizador.  Se trata de la divergencia de Kullback-Leibler entre la distribución del codificador $q_{\theta}(z|x)$ y $p(z)$. Esta divergencia mide cuánta información se pierde cuando se usa el espacio $q$  para representar $p$.

\par Otro aspecto importante del VAE es que el espacio $p(z)$ queda definido una distribución Normal de media cero varianza unidad o $p(z)=Normal(0,1)$. Si la salida de codificador difiere de esa distribución estadísticia, el codificador recibirá una penalización. 

 
\subsection{Codificación y Decodificación}

\par La eficacia y tratabildad del método reside en la asunción de que $Q(z|X)$, la función coficadora, puede ser modelada como una gaussiana con una media determinada $\mu(X)$  y varianza $\Sigma(X)$, por otro lado es necesario que $P(X)$ converja de manera eficaz a la distribución real de los datos del espacio $D$. Estas condiciones solo son superadas si y solo si $D[Q(z|X) || P(z|X)]$ es cercana a cero.
\par Es por ello necesario una función $Q$ de alta capacidad, lo cual puede llevarnos a modelos complejos. Los modelos basados en funciones usados en los VAE son las redes neuronales


\begin{figure}[htp]
\centering
\includegraphics[scale=0.7]{images/decodificador,codificador.png}
\caption{Esquematización simple de las funciones del Codificador y el Decodificador en el VAE}
\label{fig:CD_1}
\end{figure}

\par El codificador es una red neuronal. Su entrada es el dato $X$ y su salida es la representación latente $z$. Representa la distribución de probabilidad $Q(z|X)$, y esta determinada por el conjunto de parámetros y pesos de la red neuronal asociada. Denominaremos a la función encargada de la codificación $q_{\theta}(z|x)$
\par El codificador se identifica a menudo con el proceso de reducción de la dimensionalidad de $x$ a $z$. Cabe notar que el codificador tiene asociadas dos funciones, una encargada de obtener la media $q_{\mu}(X)$  y otro la varianza $q_{\Sigma}(X) $ del espacio latente. Para la obtención final de $z$ se ha de aplicar  el truco de reparametrización, ver seccion \ref{sec:repa_1}, con respecto a los valores $\Sigma$ y $\mu$ obtenidos anteriormente.

\par El decodificador es otra red neuronal. Su entrada es la variable del espacio latente $z$ y su salida es la reconstrucción del dato inicial $X$. Denominaremos a la función encargada de la decodificación $p_{\phi}(x|z)$, donde $\phi$ son el conjunto de parámetros y pesos que definen la red neuronal.

\par El hecho de que ambas funciones estén basadas en redes neuronales hace el aprendizaje profundo sea una parte primordial del VAE. Típicamente los formatos de redes neuronales aplicados en este sistema son dos; redes neuronales densas (DNN)  o redes neuronales convolucionales (CNN).

\newpage
\section{Redes Neuronales}
\par Las Redes Neuronales permiten generar funciones complejas no lineales gracias a su capacidad inherente de aprendizaje con el proceso denomiado propagación hacia atrás, que permiten ajustar los pesos de las distintas unidades o neuronas del sistema. 
\par Dada la complejidad del ámbito del aprendizaje profundo, en las siguiente seciones se pretenden exponer las ideas fundamentales para comprender el comportamiento de las funciones de codificacion y decodificación del VAE, sin entrar en explicaciones excesivamente teóricas sobre los fundamentos de las redes neuronales. 
\par Es por ello que en primer lugar se expondrá el modelo de redes neuronales densas, aprovechando para exponer de manera somera algunos conceptos de redes neuronales, como son el concepto de funciones de activación o el proceso de propagación hacia atrás. 

\par Seguidamente se expondrá el otro modelo de aprendizaje profundo utilizado en este trabajo que son las redes neuronales convolucionales, explcando por que son ideales para la captura de patrones sobre imágenes. 

\subsection{Red Neuronal Densa}
\par Este modelo constituye el paradigma básico de redes neuronales. Fundamentado en el estándar de neuronal artificial  según los principios descritos Rumelhart y McClelland en 1986 \cite{DNN_1}. Siguiendo dichos principios, la i-ésima neurona artificial  consiste en:

\begin{figure}[!hb]
\centering
\includegraphics[scale=0.5]{images/DNN_1.png}
\caption{Sistema global de proceso de una red neuronal}
\label{fig:CD_1}
\end{figure}


\begin{itemize}

\item Un conjunto de entradas $x_j$ con un conjunto de pesos sinápticos asociados $w_{ij}$, con $j=1,2...n$
\item Una regla de propagación $h_i$ a definida partir del conjunto de entradas  y de los pesos sinápticos. Normalmente la regla de propagación utilizada el producto lineal entre los pesos sinápticas y las entradas. Esto es:
\begin{center}
\begin{equation}\label{eq:DNN_1}
h_i(x_1,.....,x_m, w_{i1}....,w{in} = \sum_{i=1}^{n}w_{ij}*x_{j}
\end{equation}
\end{center}

\item Una función de activación, la cual representa simultáneamente la salida de la neurona y su estado de activación. Denotando por $y_i$ dicha función de activación:

\begin{center}
\begin{equation} \label{eq:DNN:2}
y_i = f_i(h_i) = f_i(\sum_{j=0}^{n}w_{ij}x_{j})
\end{equation}
\end{center}  

\end{itemize} 

\subsubsection{Función de Activación}
\begin{figure}[!b]
\centering
\includegraphics[scale=0.45]{images/functions_activations.png}
\caption{Principales funciones de activación.}
\label{fig:CD_1}
\end{figure}
\par La eleccion de la función de activación constituye una parte determinante en el diseño de redes neuronales, dado que afectará en gran medida al a capacidad de decisiónd de la red y la rapidez con que la red sea capaz de converger durante el entrenamiento \cite{FA_1}. 
\par En general el principal requerimiento sobre estas funciones es que sean capaces de respetar el proceso del propagación hacia atrás, no provocando que el gradiente se haga cero lo cual repercutiría negativamente en el proceso del descenso en gradiente. Este es uno de los problemas asociadas a la clasica función sigmoide, dado que para valores de $x$ ampliamente negativos o positivos, provoca que el gradiente sea cero\footnote{Este efecto es conmúnmnte denominado como saturación}, interrumpiendo el descenso en gradiente para la neurona en cuestión y, por tanto, la optimización de sus pesos sinápticos.



\begin{figure}[!hb]
\centering
\includegraphics[scale=0.45]{images/lrelu_2.png}
\caption{(izquierda) Función de activación \textit{Relu}. (Derecha) Función de activación \textit{leakyRelu.} }
\label{fig:CD_2}
\end{figure}

\par Actualmente la función de activación más utilizada es la unidad lineal de rectificación \cite{FA_2} (ReLu del inglés \textit{Rectifier Linear Unit}), representada en la figura \ref{fig:CD_1}. No obstante, otro tipo de función de activación basada en la anteriomente expuesta  denominada unidad lineal de rectificacion con pérdidas (leakyRelu) ha ganado peso en el ámbito. La única diferencia entre ambas funciones es la capacidad de la \textit{leakyRelu} de no hacer nulo el gradiente para valores negativos, ver figura \ref{fig:CD_2} para apreciar esta diferencia. En este proyecto han sido utilizadas tanto la funcion Sigmoide como la función \textit{leakyRelu}


\subsubsection{Topología de Conexionado}
\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{images/capas.png}
\caption{Esquema de una red neuronal densa de una sola capa oculta }
\label{fig:DNN_4}
\end{figure}


\par Otro concepto determinante en el comportamiento de las redes neuronales es la topología empleada, esto es, el patron de conexionado de una red neuronal. En una red neuronal artificial los nodos se conectan entre sí, siendo este conjunto de conexiones internas junto con los pesos sinápticos lo que determina el comportamiento de la red y, en última instancia, la función asociada  a la red. 
\par Las unidades neuronales suelen agruparse en lo que se denominan capas. La unión de dos o más capas constituyen una red neuronal. Se distinguen tres tipos de capas: de entrada, de salida y ocultas. Una capa de entrada esta compuesta por las neuronas que reciben las señales. Una capa de salida está constituida por el conjunto de neurones que proporcionan la respuesta de la red. Las capas ocultas no tienen conexionado con el exterior. A más capas Socultas más capacidad de aprendizaje tendrá el sistema, aunque el tiempo necesario para su optimización aumentará considerablemente. 


\subsubsection{Propagación Hacia Atrás}

Se denomina propagación hacia atrás al proceso empleado para el entrenamiento de las redes neuronales. Este entrenamiento tiene como objetivo el ajuste de los pesos sinápticos de la red. Se considera un buen ajuste de pesos aquel que minimiza el error a la salida de una red \cite{DNN_training}. De manera breve los principales pasos de este proceso de entrenamiento son:



\begin{figure}[b!]
\centering
\includegraphics[scale=0.30]{images/entrenamiento.png}
\caption{Representación esquemática del proceso de entrenamiento de una red neuronal }
\label{fig:DNN_5}
\end{figure}

\begin{itemize}
\item Inicialización. Se asigna un valor por defecto a los distintos pesos. Se considera un paso determinante, puesto que una mala inicialización puede implicar la saturación de los gradientes en los nodos.
\par Los siguientes pasos constituyen un proceso iterativo, durante el cual se irá minimizando progresivamente el error asociado a la salida de la red. 
\item Paso hacia delante  (\textit{Fast Forward}). Se comprueba el comportamiento de la red, se calcula la salida de la red para un conjunto de muestras de entrada. 
\item Estimación del error de salida. Dada una salida, se evalúa la diferencia con respecto a la salida esperada según las muestras de entrada. 
\item Se realiza la propagación hacia atrás. Dado el error a la salida se realizan el conjunto de derivadas necesarias recorriendo desde la salida hacia la entrada la red, identificando el comportamiento del gradiente del error con respecto a los diferentes pesos de la red.
\item Se modifican los pesos en función del gradiente previamente calculado. 

\end{itemize}



\newpage
\subsection{Red Neuronal Convolucional}\label{teoriaConvolucional}

\par Las redes convolucionales (CNN, del inglés \textit{Convolutional Neural Networks}) son una categoría de redes neuronales que se consideran un método altamente eficaz en áreas como el reconocimiento de imágenes \cite{CNN_1}\cite{CNN_2}.
\begin{figure}[]
\centering
\includegraphics[scale=0.50]{images/convNet.png}
\caption{Red convolucional \textit{LeNet5} }
\label{fig:CNN_1}
\end{figure}


\par Este modelo fué introducido en 1989 \cite{CNN} por Yann leCunn, la red de este trabajo fue denominada \textit{LeNet5}. Dicha red se puede observar en la imagen \ref{fig:CNN_1}
\par Las redes convoluciones suelen ser aplicadas a las imágenes. Cada imagen puede ser representada por una matriz de números sí se trata de una imagen en escala de grises, o por tres matrices sí es una imagen a color. Es esta propiedad de las imágenes donde cada dimensión, es decir cada pixel, queda definida espacialmente con respecto al resto de dimensiones, lo que convierte a las imágenes en las muestras ideales para este tipo de red. 
\par Se asume que los conjuntos de pixeles vecions formarán unas características más significativas que sí tomaramos grupos sin tener en cuenta su disposición espacial

a capa anterior lo que se emplea es el operador de convolución.
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{images/conNet_2.png}
\caption{Ejemplo de aplicación del operador convolución sobre una imagen. Seleccionada una región de la imagen cuyas dimensiones son las mismas que las del kernel seleccionado, se aplica el producto pixel a pixel entre dicha región y los pesos propios del kernel. La suma de estos productos se almacena en la imagen de salida, respetando la ubicación espacial de la región evaluada. }
\label{fig:CNN_2}
\end{figure}

\par Este tipo de redes derivan su nombre del operador de red convolución cuyo objetivo es extraer características de las imágenes preservando la relación espacial entre pixeles.  

\par Dada una imagen bidimensional \textit{I} y una  matriz $K$ de dimensiones $h\times w$ (denominada kernel de convolución) la cual es capaz de extraer algún tipo de característica relevante. La operación de convolución se puede representar como:  


\par Formalmente, se puede expresar como: 
\begin{center}
\begin{equation} \label{eq:CNN_2}
(I*K):{xy} = \sum_{i=1}^{h}\sum_{j=1}^{w} K_{ij}I_{I_{x+i-1},u+j-1}
\end{equation}
\end{center}  
 
\par A diferencia de las redes neuronales convencionales en las redes convolucionales los datos a la entrada y entre el conexionado de capas se agrupan en 3 dimensiones: ancho, alto y profundidad. En este caso nos referimos a "profundidad" por capa no a la profundidad de la red, lo cual se refiere al número de capas  de la red en cuestión. Por ejemplo, dada una imagen de entrada de tres canales (los tres canales de color) de 32x32 pixeles, la agrupación de los datos en la capa de entrada será 32x32x3. Ver figura \ref{fig:CNN_3}
\par Otra diferencia con respecto a la redes neuronales clásicas es que las unidades de una capa solo están conectadas a un espacio reducido de unidades de la capa inmediatamente anterior. 

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{images/convNet_3.png}
\caption{(Izquierda) Modelo clasico de redes neuronales. (Derecha) Modelo de Red Convolucional. Los datos son reagrupados en 3 dimensionados como se puede observar en una de las capas. Cada una de las capas tiene como entrada una imagen 3D y tiene como salida otra imagen 3D. La capa roja representa la capa de entrada por lo que la altura y la anchura son las dimensiones de la imagen y la profundidad son el número de canales}
\label{fig:CNN_3}
\end{figure}

\par Las redes neuronales convolucionales se fundamentan en tres principios básicos que son los campos receptivos locales, los pesos compartidos y el empleo de agrupaciones o \textit{pooling}

\subsubsection{Filtros Locales}

\par En una red neuronal densa, esto es, una red totalmente conectada como la de imagen \ref{fig:CNN_3} las entradas se interpretan como un conjunto "vertical" de unidades. Sin embargo, en un red convolucional es preferible organizar las unidades de entrada en forma bidimensional.
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{images/conNet_4.png}
\caption{Representación de la conectividad local en una red neuronal}
\label{fig:CNN_4}
\end{figure}

\par Las capas consecutivas estarán conectadas entre sí, pero cada unidad de una capa oculta estará conectada solo a un conjunto de unidades de la capa inmediatamente anterior.
\begin{figure}[b]
\centering
\includegraphics[scale=0.60]{images/ConvNet_6.png}
\caption{Desplazamiento del campo de recepción}
\label{fig:CNN_5}
\end{figure}


\par Se denomina filtro local a la ventana que se aplica a las diferentes regiones seleccionables de la imagen, cada una de estas régiones seleccionables estan conectadas a una única unidad de la siguiente capa oculta. A este término a menudo nos referimos como kernel. Este filtro se desplazará por toda la imagen, realizando el proceso de convolución por toda ella, ver imagen \ref{fig:CNN_5}. Es esto lo que permite extraer características de manera local por toda la imagen
\par Normalmente el desplazamiento se hace pixel a pixel aunque es posible aumentar el número de pixeles por desplazamiento. Este hiperparámetro se denomina generalmente \textit{stride}. En este trabajo se ha utilizado un valor de dos. Otro concepto a tener en cuenta es que por lo general hay varios tipos de fitros para la extracción de características en las diferentes capas.  

\subsubsection{Pesos Compartidos}

\par Cada uno de los filtros de recepción serán aplicados a toda la imagen con el mismo peso para todas las diferentes regiones. Esto significa que el patrón de selección de características será el mismo, por lo que las neuronas de la siguiente capa detectarán el mismo tipo de característica. 
\par El punto anterior se fundamente en que generalmente un patrón  de una parte de la imagen es probable que se repita en otra parte de la imagen dada la propia naturaleza de las imágenes. 
\par Con objeto de no limitar cada capa a la extracción de un tipo de característicia se aplican numeros filtros en cada una de las capas de convolución. Gracias a esto se consiguen extraer distintos tipos de patrones. 

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.40]{images/conv_net7.png}
\caption{Representación de la extracción de varias características con varios filtros}
\label{fig:CNN_6}
\end{figure}
\par Una de la ventajas del uso de pesos compartidos es que permite reducir el número de parámetros de la red. 


\begin{figure}[!htb]
\centering
\includegraphics[scale=0.50]{images/convNet_7.png}
\caption{Representación del proceso de agrupamiento (\textit{pooling})}
\label{fig:CNN_}
\end{figure}

\subsubsection{Agrupamiento}\label{agrupamiento}

\par Otro tipo de capa característica de las redes convolucionales son las capas de agrupamiento o \textit{pooling}.  Esta capa tiene como objetivo reducir el número de datos generado, realizando una estimación del valor más importante de una determinada region. Esto permite reducir progresivamente el tamaño de la imagen. Este proceso de agrupamiento se aplica individualmente a cada una de las imagnenes generadas por cada filtro.  
\par No obstante, esta funcionalidad no ha sido utilizada en el modelo generado en este trabajo dado que actualmente la librería empleada (\textit{TensorFlow})  no tiene implementada esta operación para imágenes 3D. 




\newpage
\section{Herramientas Complementarias}

\par Con objeto de evaluar la validez y la capacidad de diferenciación entre imágenes de los datos generados en la capa latente de los modelos de VAE  empleados, se han utilizado un conjunto de procedimientos de clasificación que serán expuestos en la sección \ref{sec:clasificacion}. Los fundamentos teóricos de los métodos empleados serán explicados a continuación de manera resumida.

\subsection{Máquina de Vectores de Soporte}

\par El método denominado Máquina de Vectores de Soporte (SVM, del inglés \textit{Support Vector Machine}) ha sido ampliamento usado para la clasificación y regresión \cite{SVM_1} \cite{SVM_2}, diseñado para la separación de un conjunto binario de datos, préviamente etiquetados, mediante un hiperplano, ver figura \ref{fig:SVM_1}. 

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.50]{images/svm_margin.png}
\caption{Representación de la separación binaria realizada por SVM}
\label{fig:SVM_1}
\end{figure}

\par Específicamente, se emplea un método de optimización que pretende establecer el hiperplano que logre la mayor separación posible entre clases, usando una función de decisión de la forma $R^{n}\rightarrow{}\{\pm1\}$, correspondiéndose con un espacio $n-dimensional$ de vetores de entrenamiento y etiquetas de clase $y_{i}$:


\begin{center}
\begin{equation} \label{eq:SVM_1}
(f_1,y_1),(f_2,y_2),...,(f_s, y_s) \epsilon R^{n} \times \{ \pm1\}
\end{equation}
\end{center}  

\noindent
de tal manera que $g$ es una función lineal capaz de clasificar nuevas muestras $(f,y)$. Dicha función es la encargada de definir el hiperplano de decisión y tiene la siguiente forma:

\begin{center}
\begin{equation} \label{eq:SVM_2}
g(f) = w^{T}f + v_0
\end{equation}
\end{center}  

\noindent
donde $w$ es un vector de pesos mientras que $v_0$ es el sesgo (elemento encargado de establecer el umbral entre clases). Por lo tanto, la división de clases a partir de la función $f$ será:

\begin{center}
\begin{equation} \label{eq:SVM_3}
   y_{i} = 
   \begin{cases} 
      +1  & \mbox{si } w^{T}f+v_0 \geq +1 \\
      -1  & \mbox{si } w^{T}f+v_0 \leq -1 \\ 
   \end{cases}
\end{equation}
\end{center} 

\noindent
donde el vector de pesos $w$ ha de ser ortogonal al hiperplano de decisión. El proceso de optimización es el encargado de encontrar los parámetros desconocidos de $w$ and $v_0$ de la expresión \ref{eq:SVM_2}, dichos parámetros son los que definen el hiperplano óptimo que separa las dos clases en cuestión.

\par Adicionalmente, es posbile estimar la importancia relativa de cada una de las $n$ característicias evaluadas De hecho, sea $N_{s}$ el número de vectores de soporte empledos durante la fase de entrenamiento, el siguiente vector ($W$) puede ser calculado como:

\begin{center}
\begin{equation} \label{eq:SVM_4}
 W = \sum_{j=1}^{N_s}y_j, \lambda_j, f_j,
\end{equation}
\end{center} 

\noindent
donde $y_j$ son las etiquetas de cada una de las muestras, $\lambda_{j}$ son los parámetros Lagrangianos correspondientes, los cuales también son optimizados durante la fase de entrenamiento y $f_j$  son las muestras de entremamiento. La coordenada $i$ del vector $W$, ($W_{i}$ con $1 \leq i \leq n$) hace referencia a la relevancia de la dimensión $i$ del vector de características $f_j$ \cite{SVM_3}. Más precisamente cuanto mayor sea el valor absoluto de $W_{i}$ mayor será la relevancia de la característica $i$. Por contraste $|W_i|=0$ indica que la característica $i$ no aporta ningún tipo de información en la clasificación.

\subsection{Métricas de Evaluación Estadística} \label{ch_metricasEvaluacion}


\par Hay diferentes métricas de evaluación referidas a las característiscas del diagnóstico. Algunas se utilizan para evaluar la capacidad discriminativa de la prueba y otras para estimar su propiedad de predicción, siendo esta última muy sensible a las características de las poblaciones evaluadas. 
\par Con objeto de valorar la calidad del test de diagnóstico es necesario saber cuán buena y confiable es una prueba. Esta cuantificación es llevada por el conjutno de medidas que se explicarán a continuación, las cuáles están basadas en los índices expuestos en la tabla \ref{table:metrics}.


\begin{table}[]
\centering
\label{table:metrics}
\begin{tabular}{C{3cm}C{3cm}|C{3cm}|C{3cm}|}
\cline{3-4}
  &  & \multicolumn{2}{c|}{	\textbf{Condición Real}} \\ 
\cline{3-4} 
  &  & \textbf{Positivo} & \textbf{Negativo} \\ 
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Predicción}}} & \textbf{Positivo} &  Verdadero Positivo (VP)                 &               Falso    Positivo (FP) \\ \cline{2-4} 
\multicolumn{1}{|c|}{}                            & \textbf{Negativo}     &  Falso Negativo (FN)               & Verdadero Negativo (VN)              \\ \hline
\end{tabular}
\caption{Tabla de Nomenclatura Estadística en Clasificación}
\end{table}

\subsubsection{Medida F}

\begin{center}
\begin{equation} \label{eq:p_x_gausiana}
Valor-F = \frac{*VP}{2*VP + FP + FN}
\end{equation}
\end{center}


\subsubsection{Recall. Sensibilidad}
\par La precisión mide la capacidad de una prueba diagnóstica de identificar los sujetos enfermos con respecto al total de sujetos enfermos de la población.

\begin{center}
\begin{equation} \label{eq:p_x_gausiana}
Precision = \frac{VP}{VP + FN}
\end{equation}
\end{center}


\subsubsection{Especificidad. Precisión}
\par La especificidad hace referencia a la capaciad de la prueba a identificar a los sujetos enfermos y excluir a aquellos que  no lo están. 
\begin{center}
\begin{equation} \label{eq:p_x_gausiana}
Precision = \frac{VP}{VP + FP}
\end{equation}
\end{center}

\subsubsection{Precision. Accuracy}
\par Indica la capacidad la del método de clasificación de identificar tanto pacientes sanos como pacientes enfermos con respecto al total de la población.
\begin{center}
\begin{equation} \label{eq:p_x_gausiana}
F1 = \frac{VP + VN}{NºSamples}
\end{equation}
\end{center}

\subsubsection{Curva ROC}
La curva ROC (del inglés \textit{Receiver Operating Characteristic}) es una técnica gráfica que
nos permite evaluar la precisión del modelo estadístico para clasificar dos clases, AD y
NOR. La curva se obtiene calculando la sensibilidad (proporción de resultados positivos
verdaderos) y la especificidad del modelo en cada punto de corte posible, y trazando la
sensibilidad frente a 1-especificidad (proporción de resultados falsos positivos).

\par Cada punto en el espacio ROC muestra el equilibrio entre la sensibilidad y la
especificidad, es decir, que el aumento de sensibilidad va acompañado de una disminución en la especificidad. 

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{images/curva_roc.png}
\caption{Representaciónd de la curva ROC}
\label{fig:curva_roc}
\end{figure}


\par Cada punto de corte de una prueba de diagnóstico define un único punto en el
espacio ROC, los diferentes puntos posibles definen la curva ROC. Esto es análogo a lo dicho para un solo punto, por tanto cuanto más se acerquen los puntos de la curva ROC a la coordenada ideal, más exacta será la prueba y viceversa, cuanto más se aleje peores
resultados obtendremos.

\subsubsection{Área bajo la curva}

\par El área bajo la curva ROC se denomina AUC (del inglés \textit{area under the curve}) y se interpreta como el promedio de precisiones positivas y negativas. Este índice es especialmente útil en los estudio
comparativo de pruebas de diagnóstico. Siendo deseable comparar toda la curva ROC
en lugar de en un punto particular. 



\subsection{Validación Cruzada} \label{sec_validacionCruzada}
\par La validación es una técnica utilizada para evaluar los resultados de un análisis estadístico y garantizar que son independientes de la particición entre datos de entrenamiento y de prueba. En cualquier análisis estadístico es necesario aplicar un conjunto de datos diferentes durante el entrenamiento y durante la fase de prueba, con objeto de evitar que los resultados y por tanto el sistema diseñado estén sesgados al conjunto de datos con los que se ha entrenado \cite{ValidacionCruzada}. 

\par En este trabajo, para la construcción de los conjuntos de prueba y entrenamiento se usará el método conocido como \textit{k-folds}. En este método los datos se dividen en k subconjuntos iguales, realizando k iteraciones. En cada iteración se toma uno
de los subconjuntos como datos de prueba y el resto (k-1) como datos de entrenamiento.
El proceso de validación cruzada es repetido durante k iteraciones, con cada uno de los
subconjuntos como datos de prueba, ver Fig. \ref{fig:ValidaciónCruzada}

\par Las métricas de evaluación finales se calculan como la media aritmética de las métricas cada iteración para obtener un único resultado, evitando que los resultados estén sesgados al espacio muestral. 

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{images/ValidacionCruzada.png}
\caption{Proceso de Validación Cruzada}
\label{fig:ValidaciónCruzada}
\end{figure}









































\chapterend{}