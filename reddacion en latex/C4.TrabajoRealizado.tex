%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Documento LaTeX 																						%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Título:		Capítulo 2
% Autor:  	Ignacio Moreno Doblas
% Fecha:  	2014-02-01
% Versión:	0.5.0
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapterbegin{Trabajo Realizado} 

\label{chp:Utiliz}
%\minitoc
\section{Estudio basado en régiones cerebrales}
\par Uno aspecto clave de este trabajo consiste en la división del cerebro en diferentes áreas con objeto de ser caracterizadas de manera aislada, y en última instancia, poder generar cada una de las áreas o régiones por separado. Para llevar a cabo esta separación se ha usado en atlas AAL (del inglés \textit{Automated Anatomical Labeling}) \cite{AAL} que define un total de 116 régiones las cuales se corresponden con las diferentes áreas anatómicas. Este atlas permite obtener los vóxeles asociados a cada región de manera normalizada.  

 \par Aunque  esta aproximación tiene la ventaja de permitirnos caracterizar las régiones por separado,
el principal motivo por el que hemos el alto coste computacional que lleva asociado el  uso de redes de aprendizaje profundo cuando son aplicadas en datos de alta dimensionalidad, como es nuestro caso. Otro problema derivado el amplio tiempo necesario para la caracterización de los parámetros de lared. 
\par El uso de una aproximación basada en régiones nos permite reducir de forma considerable el número de voxeles a caracterizar por cada red neuronal y por lo tanto reducir los tiempos de caracterización y los costes computacionales

\par Dentro de las 116 régiones en las que se han dividido las neuroimágenes,  normalmente aquellas a las que se les atribuye que aportan información sobre la detección del AD se las denomina Régiones de Interés (ROI, del inglés \textit{Regions of Interest}).
\par Se ha almacenado el atlas AAL junto a cada uno de las distintas modalidades de imágenes empleadas que son las MRI y las PET. Esto nos permite extraer las régiones indicades mediante el Atlas de las distintas imágenes, lo cual nos posibilita hacer el procesado de régiones de manera independiente. En la imagen se \ref{fig:Atlas} muestra un ejemplo de imagen PET y MRI con su atlas correspondiente al lado. 

\begin{figure}[htp]
\centering
\includegraphics[scale=0.55]{images/img_4.png}
\caption{MRI image (a), MRI atlas (b), (c) PET image
and (d) PET atlas (same slice is shown in MRI and PET
images)}
\label{fig:Atlas}
\end{figure} 
 


\section{Tratamiento de Neuroimágenes}
\par En todo proceso de caracterización de muestras o de aprendizaje estadístico un aspecto esencial es aplicar un tratamiento y procesado efectivo de las muestras previo al algoritmo principal, ya que si las muestras no son correctas o se producen irregularidades en su tratamiento previo se estará avocado a unos resultados incorrectos (por muy bien elaborado que esté el algoritmo principal).

\par En primer lugar se explicarán las características demográficas de las neuroimagenes empleadas. Posteriormente se expondrá de manera resumida el procesado de las imágenes realizado por el grupo de investigación de And?es Ortiz.

\subsection{Fuente de Datos}
\par Las neuroimágenes empleadas en este trabajo pertenecen a la iniciativa ADNI. Se han empleado tanto imágenes MRI como imágenes PET. Se disponen de 229 imágenes MRI de sujetos NC y 188 de sujetos de AD. Por otro lado, en el caso de las imágenes PET se disponen de 70 imágenes de sujetos AD y 68 de sujetos NC. La distribución demográfica de los sujetos se puede observar en las tablas \ref{tb:Demografia_1} y \ref{tb:Demografia_2}

\begin{table}[b]
\centering
\begin{tabular}{ c | c | c | c | c } 
 Diagnosis & Number & Age &  Gender (M/F) & MMSE  \\ \hline
 Control & 68  &  75.81 $\pm$ 4.93 & 43/25 & 29.06 $\pm$ 1.08 \\ \hline
 AD & 70  & 73.06 $\pm$ & 46/24  & 22.84 $\pm$ 2.61  

\end{tabular}
 \caption{Datos Demográficos Imágenes MRI}
\label{tb:Demografia_1}

\end{table}

\subsection{Procesado Previo}

\par Las imágenes PET y MRI de la base de datos ADNI han sido espacialmente normalizadas de acuerdo con el modelo de morfometría basada en vóxeles T1 \cite{VBM} (\textit{VBM-T1} del inglés \textit{Voxel-Based Morphology}), con objeto de garantizar que cada vóxel corresponde con la misma posición anatómica en cada una de las neuroimágenes. Posteriormente las imágenes MRI fueron redimensionadas a $121\times145\times121$ vóxeles con un tamaño de vóxel de 1.5 mm ,(Sagital) $\times$ 1.5 mm (Coronal) $\times$ 1.5 mm (axial). Por otro lado, las imágenes PET fuerón redimensionadas a $79\times95\times68$  con un tamaño de vóxel de 3 mm (Sagital) $\times$ 3 mm (Coronal) $\times$ 2 mm (axial).
\par Las imágenes MRI son tratadas de manera diferente que las PET ya que son segmentadas en tejido de materia gris (GM del inglé \textit{Grey Matter}) y tejido de materia blanca (WM del inglés \textit{White Matter}) aplicando la herramienta SPM \cite{VBM_2}\cite{VBM_3} de normalización espacial. Este proceso es  capaz de generar información sobre al distribución del tejido de GM, de WM o de fluido Cerebro-Espinal (CSF del inglés \textit{Cerebrospinal Fluid}) en las neuroimágenes, quedando caracterizado por una probabilidad de pertenencia  para cada uno de los tejidos de rango [0, 1]. 

\begin{figure}[htp]
\centering
\includegraphics[scale=0.55]{images/ejemplo_MRI.png}
\caption{Muestra de neuroimagen MRI segmentada. (zquierda) MRI WM image. (Derecha) MRI GM image}
\label{fig:Atlas}
\end{figure} 


\par Por otro lado, las imágenes PET son normalizadas con respecto al nivel de intensidad. Este nivel máximo de intensidad se toma a partir del nivel medio del 1\%  de los vóxeles con mayor activación del cerebelo \cite{PET_norm}, dado que esta región cerebral es considerada con activación constante. Este proceso de normalización  permite la homogeanización de los niveles entre los vóxeles permitiéndonse las posterior comparación entre vóxeles. 


\begin{figure}[htp]
\centering
\includegraphics[scale=0.4]{images/ejemplo_PET.png}
\caption{Muestra de neuroimagen PET normalizada}
\label{fig:Imagen PET normalizada}
\end{figure} 


\subsubsection{Preselección de Vóxeles}
\par La preseleción de vóxeles se ha aplicado a cada modalidad de imagen con objeto de eliminar los vóxeles poco significativos. Esto nos permite reducir el alto coste computacional asociado a la alta dimensionalidad de las imágenes. Esta preselección de características ha sido realizada mediante el \textit{t-test de Welch} sepradamente sobre cada tipo de imagen. 

\par El \textit{t-test Welch} permite evaluar la diferencia entre la media de dos espacios muestrales, en nuestro caso NC y AD, cuando las varianzas no son iguales y puede ser calculado usando la siguiente expresión:


\begin{center}
\begin{equation} \label{eq:t-test}
I^{t}  = \frac{I_{NC}^{\mu} - I_{AD}^{\mu}}{ \sqrt{\frac{I_{NC}^{\sigma}}{N_{NC}} + \frac{I_{AD}^{\sigma}}{N_{AD}}  }}
\end{equation}
\end{center}

\par donde $I_{NC}^{\mu}$ y $I_{AD}^{\mu}$ son las medias de las imagenes de los sujetos NC y AD respectivamente, mientras que  $I_{NC}^{\sigma}$ y $I_{AD}^{\sigma}$ son las varianzas de las imagenes y $N_{NC}, N_{AD}$ son el número de muestras NC y AD. Las imagenes de medias  $I_{NC}^{\mu}$ y $I_{AD}^{\mu}$ se calculan como:

\begin{center}
\begin{equation} \label{eq:t-test-means}
I_{NC}^{\mu} = \frac{1}{N_{NC}}\sum_{j=1}^{N_{NC}}I_{j}, \quad I_{AD}^{\mu} = \frac{1}{N_{AD}}\sum_{j=1}^{N_{AD}}I_{j},
\end{equation}
\end{center}

mientras que las varianzas de las imágenes $I_{NC}^{\sigma}$ y $I_{AD}^{\sigma}$ son calculadas mediante:

\begin{center}
\begin{equation} \label{eq:t-test-vars}
I_{NC}^{\sigma} = \frac{1}{N_{NC}}\sum_{j=1}^{N_{NC}}(I_{j} - I_{j}^{\mu})^2, \quad I_{AD}^{\sigma} = \frac{1}{N_{AD}}\sum_{j=1}^{N_{AD}}(I_{j} - I_{j}^{\mu})^2
\end{equation}
\end{center}

\par En la ecuación \ref{eq:t-test} el término $I^{t}$ corresponde al valor del test \textit{Welch} para cada uno de los vóxeles de la imagen, lo cual es una medida significativa de la diferencia de medias. De manera intuitiva un alto valor de este elemento indica que hay una diferencia significativa entre las muestras de un espacio y otro, y, por lo tanto, el vóxel en cuestión es significativo. 
\par De manera teórica, altos valores del test (\textit{t-valor}) se corresponden con valores bajos de probabilidad (\textit{p-valor}), donde se referencia por \textit{p-valor} la probabilidad de observar un valor \textit{t-valor}. Queda definida la hipótesis nula en la igualdad entre las medias de imágenes. Por lo tanto, valores pequeños de $p$ indicarán el rechazo de la hipótesis nula en cuestión.
\par En nuestro caso, se ha fijado el umbral de decisión sobre la hipótesis nula en $p-valor < 0.05$, esto es, un valor de significancia del 5\%.

\subsection{Segmentación basada en régiones}
\par Tal y como se ha comentado al principio de este capítulo, un aspecto básico de el trabajo realizado es la división o segmentación de las neuroimágenes en régiones para su estudio posterior, lo cual conlleva un procesado asociado.
\par Dado que se han empleado dos modelos de aprendizaje bien diferenciados será necesario llevar a cabo una segmentación de régiones diferente para cada tipo. Uno de los modelos de aprendizaje está basada en el estudio de las imagenes 3D de las régiones mientras que el otro está basado en caracterizar un vector de vóxeles pertenecientes a la región estudiada.

\par Cabe mencionar los componentes iniciales de este proceso:
\begin{itemize}
\item \textbf{ Vector de vóxeles de  imagen}. Por cada neuroimagen de cada paciente, ya sea una imagen PET o MRI  se tendrá un vector de vóxeles asociado. Este vector contiene los valores de intensidad de los vóxeles dispuesto en forma vectorial en lugar de en una imagen 3D.
\item \textbf{Atlas AAL}.  El Atlas contiene un total de 116 listas distintas, cada una de ellas asociadas a una de las regiones. Cada lista contiene un conjunto de índices referidos a la posición de los vóxeles que pertenecen a la región en cuestión a la que hace referencia la lista. 
\end{itemize}

\subsubsection{Segmentación en vectores 1D}

\par Este tratamiento tiene como objetivo generar un vector de vóxeles para cada una de las 116 régiones del atlas \textit{AAL}. El procedimiento queda representado en la imagen \ref{fig:Segm1}. El principal aspecto a comentar es que cada región tendrá un número de vóxeles asociado diferente, encargándose el atlas AAL de seleccionar cuales son los vóxeles pertenecientes a cada región tras la previa selección de los voxeles significativos. 
\par Cabe notar como para cada región tendremos un número de voxeles distinto. En la tabla \ref{tb:MRI_voxels_per_region} se observa la amplia diferencia entre régiones en las imágenes MRI.

\begin{figure}[htp] 

\centering
\includegraphics[scale=0.4]{images/Segmentacion_1D.png}
\caption{Proceso de segmentación de vectores por región}
\label{fig:Segm1}
\end{figure} 

\begin{table}[b]
\centering
\begin{tabular}{ c | c } 
Región &  NºVóxeles \\ \hline
1 & 8272 \\ \hline
20 & 5535 \\ \hline
40 & 2708 \\ \hline
60 & 5191 \\ \hline
80 & 567 \\ \hline
100 & 4260 \\ \hline
116 & 560 
\end{tabular}
\caption{Número de vóxeles en imagen MRI por cada región}
\label{tb:MRI_voxels_per_region}
\end{table}




\subsubsection{Segmentación en imágenes 3D}

\par En el caso de la obtención de las régiones cerebrales en imagenes 3D se ha realizado un procesado basado en la obtención de una máscara 3D sobre los índices de vóxeles del atlas AAL. Para ello, se ha reconstruido el atlas, extrayendo de aquí los límites en cada una de las dimensiones de la posición de la región evaluada. 
\par Posteriormente, se ha usado este conocimiento de la posición exacta de los vóxeles en 3D para llevar a cabao la extracción de la región en cuestión. Este proceso ha sido esquematizado en la imagen \ref{fig:Segm3}. En la imagen \ref{fig:Segm3_example} se pueden observar dos régiones extraídas y representadas en 3D. 

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.35]{images/Segmentacion_3D.png}
\caption{Proceso de segmentación de vectores por región}
\label{fig:Segm3}
\end{figure} 

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{images/pet_3d.png}
\caption{Ejemplo de Régiones de imágenes PET segmentadas.(Izquierda) Región Nº 20. (Derecha) Región Nº 30. Capturas de imágenes 3D tomadas con el programa \textit{MRIcrGL}}
\label{fig:Segm3_example}
\end{figure} 

\subsection{Reconstrucción a partir de Régiones}


\newpage
\section{Modelos Generativos}
asddfasdf
\newpage
\section{Modelos de Clasificación}
asdfasdf






































\chapterend{}