%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Documento LaTeX 																						%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Título:		Capítulo 2
% Autor:  	Ignacio Moreno Doblas
% Fecha:  	2014-02-01
% Versión:	0.5.0
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapterbegin{Trabajo Realizado} 

\label{chp:Utiliz}
%\minitoc
\section{Estudio basado en régiones cerebrales}
\par Uno aspecto clave de este trabajo consiste en la división del cerebro en diferentes áreas con objeto de ser caracterizadas de manera aislada, y en última instancia, poder generar cada una de las áreas o régiones por separado. Para llevar a cabo esta separación se ha usado en atlas AAL (del inglés \textit{Automated Anatomical Labeling}) \cite{AAL} que define un total de 116 régiones las cuales se corresponden con las diferentes áreas anatómicas. Este atlas permite obtener los vóxeles asociados a cada región de manera normalizada.  

 \par Aunque  esta aproximación tiene la ventaja de permitirnos caracterizar las régiones por separado,
el principal motivo por el que hemos el alto coste computacional que lleva asociado el  uso de redes de aprendizaje profundo cuando son aplicadas en datos de alta dimensionalidad, como es nuestro caso. Otro problema derivado el amplio tiempo necesario para la caracterización de los parámetros de lared. 
\par El uso de una aproximación basada en régiones nos permite reducir de forma considerable el número de voxeles a caracterizar por cada red neuronal y por lo tanto reducir los tiempos de caracterización y los costes computacionales

\par Dentro de las 116 régiones en las que se han dividido las neuroimágenes,  normalmente aquellas a las que se les atribuye que aportan información sobre la detección del AD se las denomina Régiones de Interés (ROI, del inglés \textit{Regions of Interest}).
\par Se ha almacenado el atlas AAL junto a cada uno de las distintas modalidades de imágenes empleadas que son las MRI y las PET. Esto nos permite extraer las régiones indicades mediante el Atlas de las distintas imágenes, lo cual nos posibilita hacer el procesado de régiones de manera independiente. En la imagen se \ref{fig:Atlas} muestra un ejemplo de imagen PET y MRI con su atlas correspondiente al lado. 

\begin{figure}[htp]
\centering
\includegraphics[scale=0.55]{images/img_4.png}
\caption{MRI image (a), MRI atlas (b), (c) PET image
and (d) PET atlas (same slice is shown in MRI and PET
images)}
\label{fig:Atlas}
\end{figure} 
 


\section{Tratamiento de Neuroimágenes}
\par En todo proceso de caracterización de muestras o de aprendizaje estadístico un aspecto esencial es aplicar un tratamiento y procesado efectivo de las muestras previo al algoritmo principal, ya que si las muestras no son correctas o se producen irregularidades en su tratamiento previo se estará avocado a unos resultados incorrectos (por muy bien elaborado que esté el algoritmo principal).

\par En primer lugar se explicarán las características demográficas de las neuroimagenes empleadas. Posteriormente se expondrá de manera resumida el procesado de las imágenes realizado por el grupo de investigación de And?es Ortiz.

\subsection{Fuente de Datos}
\par Las neuroimágenes empleadas en este trabajo pertenecen a la iniciativa ADNI. Se han empleado tanto imágenes MRI como imágenes PET. Se disponen de 229 imágenes MRI de sujetos NC y 188 de sujetos de AD. Por otro lado, en el caso de las imágenes PET se disponen de 70 imágenes de sujetos AD y 68 de sujetos NC. La distribución demográfica de los sujetos se puede observar en las tablas \ref{tb:Demografia_1} y \ref{tb:Demografia_2}

\begin{table}[b]
\centering
\begin{tabular}{ c | c | c | c | c } 
 Diagnosis & Number & Age &  Gender (M/F) & MMSE  \\ \hline
 Control & 68  &  75.81 $\pm$ 4.93 & 43/25 & 29.06 $\pm$ 1.08 \\ \hline
 AD & 70  & 73.06 $\pm$ & 46/24  & 22.84 $\pm$ 2.61  

\end{tabular}
 \caption{Datos Demográficos Imágenes MRI}
\label{tb:Demografia_1}

\end{table}

\subsection{Procesado Previo}

\par Las imágenes PET y MRI de la base de datos ADNI han sido espacialmente normalizadas de acuerdo con el modelo de morfometría basada en vóxeles T1 \cite{VBM} (\textit{VBM-T1} del inglés \textit{Voxel-Based Morphology}), con objeto de garantizar que cada vóxel corresponde con la misma posición anatómica en cada una de las neuroimágenes. Posteriormente las imágenes MRI fueron redimensionadas a $121\times145\times121$ vóxeles con un tamaño de vóxel de 1.5 mm ,(Sagital) $\times$ 1.5 mm (Coronal) $\times$ 1.5 mm (axial). Por otro lado, las imágenes PET fuerón redimensionadas a $79\times95\times68$  con un tamaño de vóxel de 3 mm (Sagital) $\times$ 3 mm (Coronal) $\times$ 2 mm (axial).
\par Las imágenes MRI son tratadas de manera diferente que las PET ya que son segmentadas en tejido de materia gris (GM del inglé \textit{Grey Matter}) y tejido de materia blanca (WM del inglés \textit{White Matter}) aplicando la herramienta SPM \cite{VBM_2}\cite{VBM_3} de normalización espacial. Este proceso es  capaz de generar información sobre al distribución del tejido de GM, de WM o de fluido Cerebro-Espinal (CSF del inglés \textit{Cerebrospinal Fluid}) en las neuroimágenes, quedando caracterizado por una probabilidad de pertenencia  para cada uno de los tejidos de rango [0, 1]. 

\begin{figure}[htp]
\centering
\includegraphics[scale=0.55]{images/ejemplo_MRI.png}
\caption{Muestra de neuroimagen MRI segmentada. (zquierda) MRI WM image. (Derecha) MRI GM image}
\label{fig:Atlas}
\end{figure} 


\par Por otro lado, las imágenes PET son normalizadas con respecto al nivel de intensidad. Este nivel máximo de intensidad se toma a partir del nivel medio del 1\%  de los vóxeles con mayor activación del cerebelo \cite{PET_norm}, dado que esta región cerebral es considerada con activación constante. Este proceso de normalización  permite la homogeanización de los niveles entre los vóxeles permitiéndonse las posterior comparación entre vóxeles. 


\begin{figure}[htp]
\centering
\includegraphics[scale=0.4]{images/ejemplo_PET.png}
\caption{Muestra de neuroimagen PET normalizada}
\label{fig:Imagen PET normalizada}
\end{figure} 


\subsubsection{Preselección de Vóxeles}
\par La preseleción de vóxeles se ha aplicado a cada modalidad de imagen con objeto de eliminar los vóxeles poco significativos. Esto nos permite reducir el alto coste computacional asociado a la alta dimensionalidad de las imágenes. Esta preselección de características ha sido realizada mediante el \textit{t-test de Welch} sepradamente sobre cada tipo de imagen. 

\par El \textit{t-test Welch} permite evaluar la diferencia entre la media de dos espacios muestrales, en nuestro caso NC y AD, cuando las varianzas no son iguales y puede ser calculado usando la siguiente expresión:


\begin{center}
\begin{equation} \label{eq:t-test}
I^{t}  = \frac{I_{NC}^{\mu} - I_{AD}^{\mu}}{ \sqrt{\frac{I_{NC}^{\sigma}}{N_{NC}} + \frac{I_{AD}^{\sigma}}{N_{AD}}  }}
\end{equation}
\end{center}

\par donde $I_{NC}^{\mu}$ y $I_{AD}^{\mu}$ son las medias de las imagenes de los sujetos NC y AD respectivamente, mientras que  $I_{NC}^{\sigma}$ y $I_{AD}^{\sigma}$ son las varianzas de las imagenes y $N_{NC}, N_{AD}$ son el número de muestras NC y AD. Las imagenes de medias  $I_{NC}^{\mu}$ y $I_{AD}^{\mu}$ se calculan como:

\begin{center}
\begin{equation} \label{eq:t-test-means}
I_{NC}^{\mu} = \frac{1}{N_{NC}}\sum_{j=1}^{N_{NC}}I_{j}, \quad I_{AD}^{\mu} = \frac{1}{N_{AD}}\sum_{j=1}^{N_{AD}}I_{j},
\end{equation}
\end{center}

mientras que las varianzas de las imágenes $I_{NC}^{\sigma}$ y $I_{AD}^{\sigma}$ son calculadas mediante:

\begin{center}
\begin{equation} \label{eq:t-test-vars}
I_{NC}^{\sigma} = \frac{1}{N_{NC}}\sum_{j=1}^{N_{NC}}(I_{j} - I_{j}^{\mu})^2, \quad I_{AD}^{\sigma} = \frac{1}{N_{AD}}\sum_{j=1}^{N_{AD}}(I_{j} - I_{j}^{\mu})^2
\end{equation}
\end{center}

\par En la ecuación \ref{eq:t-test} el término $I^{t}$ corresponde al valor del test \textit{Welch} para cada uno de los vóxeles de la imagen, lo cual es una medida significativa de la diferencia de medias. De manera intuitiva un alto valor de este elemento indica que hay una diferencia significativa entre las muestras de un espacio y otro, y, por lo tanto, el vóxel en cuestión es significativo. 
\par De manera teórica, altos valores del test (\textit{t-valor}) se corresponden con valores bajos de probabilidad (\textit{p-valor}), donde se referencia por \textit{p-valor} la probabilidad de observar un valor \textit{t-valor}. Queda definida la hipótesis nula en la igualdad entre las medias de imágenes. Por lo tanto, valores pequeños de $p$ indicarán el rechazo de la hipótesis nula en cuestión.
\par En nuestro caso, se ha fijado el umbral de decisión sobre la hipótesis nula en $p-valor < 0.05$, esto es, un valor de significancia del 5\%.

\subsection{Segmentación basada en régiones}
\par Tal y como se ha comentado al principio de este capítulo, un aspecto básico de el trabajo realizado es la división o segmentación de las neuroimágenes en régiones para su estudio posterior, lo cual conlleva un procesado asociado.
\par Dado que se han empleado dos modelos de aprendizaje bien diferenciados será necesario llevar a cabo una segmentación de régiones diferente para cada tipo. Uno de los modelos de aprendizaje está basada en el estudio de las imagenes 3D de las régiones mientras que el otro está basado en caracterizar un vector de vóxeles pertenecientes a la región estudiada.

\par Cabe mencionar los componentes iniciales de este proceso:
\begin{itemize}
\item \textbf{ Vector de vóxeles de  imagen}. Por cada neuroimagen de cada paciente, ya sea una imagen PET o MRI  se tendrá un vector de vóxeles asociado. Este vector contiene los valores de intensidad de los vóxeles dispuesto en forma vectorial en lugar de en una imagen 3D.
\item \textbf{Atlas AAL}.  El Atlas contiene un total de 116 listas distintas, cada una de ellas asociadas a una de las regiones. Cada lista contiene un conjunto de índices referidos a la posición de los vóxeles que pertenecen a la región en cuestión a la que hace referencia la lista. 
\end{itemize}

\subsubsection{Segmentación en vectores 1D}

\par Este tratamiento tiene como objetivo generar un vector de vóxeles para cada una de las 116 régiones del atlas \textit{AAL}. El procedimiento queda representado en la imagen \ref{fig:Segm1}. El principal aspecto a comentar es que cada región tendrá un número de vóxeles asociado diferente, encargándose el atlas AAL de seleccionar cuales son los vóxeles pertenecientes a cada región tras la previa selección de los voxeles significativos. 
\par Cabe notar como para cada región tendremos un número de voxeles distinto. En la tabla \ref{tb:MRI_voxels_per_region} se observa la amplia diferencia entre régiones en las imágenes MRI.

\begin{figure}[htp] 

\centering
\includegraphics[scale=0.4]{images/Segmentacion_1D.png}
\caption{Proceso de segmentación de vectores por región}
\label{fig:Segm1}
\end{figure} 

\begin{table}[b]
\centering
\begin{tabular}{ c | c } 
Región &  NºVóxeles \\ \hline
1 & 8272 \\ \hline
20 & 5535 \\ \hline
40 & 2708 \\ \hline
60 & 5191 \\ \hline
80 & 567 \\ \hline
100 & 4260 \\ \hline
116 & 560 
\end{tabular}
\caption{Número de vóxeles en imagen MRI por cada región}
\label{tb:MRI_voxels_per_region}
\end{table}




\subsubsection{Segmentación en imágenes 3D}

\par En el caso de la obtención de las régiones cerebrales en imagenes 3D se ha realizado un procesado basado en la obtención de una máscara 3D sobre los índices de vóxeles del atlas AAL. Para ello, se ha reconstruido el atlas, extrayendo de aquí los límites en cada una de las dimensiones de la posición de la región evaluada. 
\par Posteriormente, se ha usado este conocimiento de la posición exacta de los vóxeles en 3D para llevar a cabao la extracción de la región en cuestión. Este proceso ha sido esquematizado en la imagen \ref{fig:Segm3}. En la imagen \ref{fig:Segm3_example} se pueden observar dos régiones extraídas y representadas en 3D. 

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.35]{images/Segmentacion_3D.png}
\caption{Proceso de segmentación de vectores por región}
\label{fig:Segm3}
\end{figure} 

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{images/pet_3d.png}
\caption{Ejemplo de Régiones de imágenes PET segmentadas.(Izquierda) Región Nº 20. (Derecha) Región Nº 30. Capturas de imágenes 3D tomadas con el programa \textit{MRIcrGL}}
\label{fig:Segm3_example}
\end{figure} 

\subsection{Reconstrucción a partir de Régiones}


\newpage
\section{Modelos Generativos}
asddfasdf
\newpage
\section{Modelo de Clasificación}
\par El diseño y aplicación de un modelo de clasificación es de especial interés dado que la capacidad de clasificación esta intimamente relacionada con el método de extracción características empleado, que en nuestro caso será el autoencoder variacional.


\par Tal y como ya se ha explicado préviamente, el autoencoder es capaz generar un conjunto de características representativas en lo que se denomina espacio latente, siendo estas variables obtenidas sobre las que posteriormente se les aplicará el proceso de clasificación. Estas variables latentes serán genereadas por región, por lo que al final tendremos tantos vectores de variables latentes como número de régiones se estén evaluando.

\par Es importante notar que el procesamiento de las régiones por separado implica la aplicación de un procedimiento de clasificación en el cuál debemos de unir la información de evaluación de cada región. En la figura \ref{fig:main_clasificacion} se puede apreciar lo mencionado anteriormente.

\par A lo largo de esta sección se detallará el método explicando el procedimiento realizado y mencionando algunas de las problemáticas encontradas como son la extracción de características por región o el mezclado de información para los dos tipo de imágenes MRI.


\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/ClasificacionMainEsquema.png}
\caption{Esquema básico de Autoencoder. Cabe notar como será el código generado en la capa latente lo que se empleará para la clasificación posterior}
\label{fig:main_clasificacion}
\end{figure} 

\par 


\subsection{Extracción de Características por Región}
\par El proceso de extracción de características aplica el Autoencoder Variacional. Una esquematización de dicho proceso se puede observar en la imagen \ref{fig:Extracción_1}. Es de esperar que el aumento del tamaño de la capa latente, esto es, que haya más neuronas en dicha capa conlleve una mejora en los resultados de la clasificación dado que se ha comprimido menos la información de las imágenes.

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/RegionExtractFeatures.png}
\caption{Diagrama básico del proceso de extracción de características aplicando el Autoencoder Variacional}
\label{fig:Extracción_1}
\end{figure} 



\par Se pueden diferencia dos fases, la de entrenamiento y la de extracción de características, mientras que el tercer bloque de la figura \ref{fig:Extracción_1} hace referencia al vector de variables esperadas a la salida.
\begin{itemize}
\item \textbf{Entrenamiento del Autoencoder}. El entrenamiento tiene como objetivo caracterizar el Autoencoder en función del tipo de muestra, en nuestro caso en función de la tipología de neuroimagen de cada una de las régiones evaluadas. Es este entrenamiento el proceso mas costoso, tanto computacionalmente como en términos de coste en el desarrollo de este modelo de clasificación. 
\par Este proceso permite la extracción efectiva de características ya que es el que ajusta el conjunto de parámetros encargados de generar el conjunto de variables latentes en función del tipo de imagen de entrada. 

\item \textbf{Codificación}. Dado el conjunto de vóxeles de cada neuroimagensociado a un tipo de región, este proceso se encargará de generar el conjunto de varibles latentes.

\end{itemize}

\par En esta fase es posible aplicar tanto el VAE de capas densas como el CVAE dado que lo importante es garantizar que la salida será un vector de variables sin importar el procedimiento de extracción empleado. No obstante, el tipo de VAE empleado modificará el procesado previo de las imagenes dado que si se emplea el VAE de redes densa se deberán vectorizar las imágenes mientras que si es el CVAE se deberá delimitar en 3D las distintas regiones.

\par Un aspecto diferencial en el tratamiento de las imágenes PET y MRI es que para las MRI tenemos dos modalidades de imágenes, las de materia blanca y las de materia gris, es por ello que para las imágenes MRI necesitaremos dos \textit{Autoencoders} lo cual duplica el coste computacional. En la figura \ref{fig:Extracion_MRI} queda representado este concepto

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/RegionExtractFeaturesMRI.png}
\caption{Diagrama básico del proceso de extracción de características para las imágenes MRI}
\label{fig:Extracción_MRI}
\end{figure} 

\par Por lo tanto, para el caso de las imágenes MRI se tendrá a la salida un vector de características que será la concatenación de las variables latentes obtenidas a partir de las imágenes de materia blanca y materia gris.





\newpage
\subsection{Evaluación por Región}

\


\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/ExtracccionCaracteristicasVAE.png}
\caption{Esquema del proceso de extracción de características aplicando el autoencoder variacional. Es importante notar como el procesamiento y al extracción de las características para cada una de las régiones evaluadas se reliaza por separado y es posteriormente cuando la información de las distintas régiones es concatenada}
\label{fig:Clasificacion_2}
\end{figure} 



\newpage
\subsection{Evaluación Conjunta}

\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/Autoencoder.png}
\caption{Esquema básico del proceso de clasificación}
\label{fig:Codifiación}
\end{figure} 

\par 



\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/Clasificacion.png}
\caption{}
Falta el SVM 
\label{fig:Clasificacion_1}
\end{figure} 






\begin{figure}[htp] 
\centering
\includegraphics[scale=0.5]{diagrams/MRIClasificacionVAE.png}
\caption{Este esq}
\label{fig:Clasificacion_3}
\end{figure} 


\par En el caso de las imágenes MRI el procedimiento empleado en el procesamiento de las régiones es parcialmente diferente. 



Falta el SVM 




































\chapterend{}